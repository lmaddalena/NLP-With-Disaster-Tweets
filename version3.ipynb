{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle - Natural Language Processing with Disaster Tweets\n",
    "### Predict which Tweets are about real disasters and which ones are not\n",
    "https://www.kaggle.com/competitions/nlp-getting-started/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import transformers as ppb \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape = (7613, 5)\n",
      "Training Set Memory Usage = 0.29 MB\n",
      "Test Set Shape = (3263, 4)\n",
      "Test Set Memory Usage = 0.10 MB\n"
     ]
    }
   ],
   "source": [
    "print('Training Set Shape = {}'.format(df_train.shape))\n",
    "print('Training Set Memory Usage = {:.2f} MB'.format(df_train.memory_usage().sum() / 1024**2))\n",
    "print('Test Set Shape = {}'.format(df_test.shape))\n",
    "print('Test Set Memory Usage = {:.2f} MB'.format(df_test.memory_usage().sum() / 1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">id</th>\n",
       "      <th colspan=\"8\" halign=\"left\">target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ablaze</th>\n",
       "      <td>36.0</td>\n",
       "      <td>70.388889</td>\n",
       "      <td>14.035216</td>\n",
       "      <td>48.0</td>\n",
       "      <td>58.50</td>\n",
       "      <td>69.5</td>\n",
       "      <td>81.25</td>\n",
       "      <td>95.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.487136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accident</th>\n",
       "      <td>35.0</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>15.118746</td>\n",
       "      <td>96.0</td>\n",
       "      <td>109.50</td>\n",
       "      <td>121.0</td>\n",
       "      <td>134.50</td>\n",
       "      <td>145.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.471008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aftershock</th>\n",
       "      <td>34.0</td>\n",
       "      <td>171.323529</td>\n",
       "      <td>13.975564</td>\n",
       "      <td>146.0</td>\n",
       "      <td>160.25</td>\n",
       "      <td>171.5</td>\n",
       "      <td>182.75</td>\n",
       "      <td>195.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airplane%20accident</th>\n",
       "      <td>35.0</td>\n",
       "      <td>220.142857</td>\n",
       "      <td>15.406536</td>\n",
       "      <td>196.0</td>\n",
       "      <td>208.50</td>\n",
       "      <td>219.0</td>\n",
       "      <td>233.50</td>\n",
       "      <td>245.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.355036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ambulance</th>\n",
       "      <td>38.0</td>\n",
       "      <td>269.052632</td>\n",
       "      <td>14.101845</td>\n",
       "      <td>246.0</td>\n",
       "      <td>258.50</td>\n",
       "      <td>268.5</td>\n",
       "      <td>279.75</td>\n",
       "      <td>294.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.506009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wounded</th>\n",
       "      <td>37.0</td>\n",
       "      <td>10609.135135</td>\n",
       "      <td>14.491688</td>\n",
       "      <td>10585.0</td>\n",
       "      <td>10598.00</td>\n",
       "      <td>10609.0</td>\n",
       "      <td>10622.00</td>\n",
       "      <td>10632.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.463373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wounds</th>\n",
       "      <td>33.0</td>\n",
       "      <td>10662.393939</td>\n",
       "      <td>14.225724</td>\n",
       "      <td>10636.0</td>\n",
       "      <td>10651.00</td>\n",
       "      <td>10663.0</td>\n",
       "      <td>10675.00</td>\n",
       "      <td>10684.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.466694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wreck</th>\n",
       "      <td>37.0</td>\n",
       "      <td>10708.513514</td>\n",
       "      <td>15.230856</td>\n",
       "      <td>10685.0</td>\n",
       "      <td>10695.00</td>\n",
       "      <td>10708.0</td>\n",
       "      <td>10722.00</td>\n",
       "      <td>10733.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.397061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wreckage</th>\n",
       "      <td>39.0</td>\n",
       "      <td>10759.717949</td>\n",
       "      <td>14.730828</td>\n",
       "      <td>10735.0</td>\n",
       "      <td>10747.50</td>\n",
       "      <td>10760.0</td>\n",
       "      <td>10771.50</td>\n",
       "      <td>10784.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrecked</th>\n",
       "      <td>39.0</td>\n",
       "      <td>10810.692308</td>\n",
       "      <td>15.178159</td>\n",
       "      <td>10785.0</td>\n",
       "      <td>10798.50</td>\n",
       "      <td>10812.0</td>\n",
       "      <td>10823.50</td>\n",
       "      <td>10834.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.269953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                              \\\n",
       "                    count          mean        std      min       25%   \n",
       "keyword                                                                 \n",
       "ablaze               36.0     70.388889  14.035216     48.0     58.50   \n",
       "accident             35.0    121.800000  15.118746     96.0    109.50   \n",
       "aftershock           34.0    171.323529  13.975564    146.0    160.25   \n",
       "airplane%20accident  35.0    220.142857  15.406536    196.0    208.50   \n",
       "ambulance            38.0    269.052632  14.101845    246.0    258.50   \n",
       "...                   ...           ...        ...      ...       ...   \n",
       "wounded              37.0  10609.135135  14.491688  10585.0  10598.00   \n",
       "wounds               33.0  10662.393939  14.225724  10636.0  10651.00   \n",
       "wreck                37.0  10708.513514  15.230856  10685.0  10695.00   \n",
       "wreckage             39.0  10759.717949  14.730828  10735.0  10747.50   \n",
       "wrecked              39.0  10810.692308  15.178159  10785.0  10798.50   \n",
       "\n",
       "                                                target                      \\\n",
       "                         50%       75%      max  count      mean       std   \n",
       "keyword                                                                      \n",
       "ablaze                  69.5     81.25     95.0   36.0  0.361111  0.487136   \n",
       "accident               121.0    134.50    145.0   35.0  0.685714  0.471008   \n",
       "aftershock             171.5    182.75    195.0   34.0  0.000000  0.000000   \n",
       "airplane%20accident    219.0    233.50    245.0   35.0  0.857143  0.355036   \n",
       "ambulance              268.5    279.75    294.0   38.0  0.526316  0.506009   \n",
       "...                      ...       ...      ...    ...       ...       ...   \n",
       "wounded              10609.0  10622.00  10632.0   37.0  0.702703  0.463373   \n",
       "wounds               10663.0  10675.00  10684.0   33.0  0.303030  0.466694   \n",
       "wreck                10708.0  10722.00  10733.0   37.0  0.189189  0.397061   \n",
       "wreckage             10760.0  10771.50  10784.0   39.0  1.000000  0.000000   \n",
       "wrecked              10812.0  10823.50  10834.0   39.0  0.076923  0.269953   \n",
       "\n",
       "                                              \n",
       "                     min  25%  50%  75%  max  \n",
       "keyword                                       \n",
       "ablaze               0.0  0.0  0.0  1.0  1.0  \n",
       "accident             0.0  0.0  1.0  1.0  1.0  \n",
       "aftershock           0.0  0.0  0.0  0.0  0.0  \n",
       "airplane%20accident  0.0  1.0  1.0  1.0  1.0  \n",
       "ambulance            0.0  0.0  1.0  1.0  1.0  \n",
       "...                  ...  ...  ...  ...  ...  \n",
       "wounded              0.0  0.0  1.0  1.0  1.0  \n",
       "wounds               0.0  0.0  0.0  1.0  1.0  \n",
       "wreck                0.0  0.0  0.0  0.0  1.0  \n",
       "wreckage             1.0  1.0  1.0  1.0  1.0  \n",
       "wrecked              0.0  0.0  0.0  0.0  1.0  \n",
       "\n",
       "[221 rows x 16 columns]"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby([\"keyword\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword\n",
       "ablaze                 36\n",
       "accident               35\n",
       "aftershock             34\n",
       "airplane%20accident    35\n",
       "ambulance              38\n",
       "                       ..\n",
       "wounded                37\n",
       "wounds                 33\n",
       "wreck                  37\n",
       "wreckage               39\n",
       "wrecked                39\n",
       "Name: keyword, Length: 221, dtype: int64"
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby([\"keyword\"])[\"keyword\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ablaze</th>\n",
       "      <td>14.0</td>\n",
       "      <td>70.785714</td>\n",
       "      <td>16.446550</td>\n",
       "      <td>46.0</td>\n",
       "      <td>58.5</td>\n",
       "      <td>71.0</td>\n",
       "      <td>86.25</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accident</th>\n",
       "      <td>15.0</td>\n",
       "      <td>117.466667</td>\n",
       "      <td>13.211827</td>\n",
       "      <td>99.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>124.50</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aftershock</th>\n",
       "      <td>16.0</td>\n",
       "      <td>168.750000</td>\n",
       "      <td>16.114176</td>\n",
       "      <td>147.0</td>\n",
       "      <td>153.5</td>\n",
       "      <td>168.0</td>\n",
       "      <td>182.25</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airplane%20accident</th>\n",
       "      <td>15.0</td>\n",
       "      <td>221.333333</td>\n",
       "      <td>12.893335</td>\n",
       "      <td>200.0</td>\n",
       "      <td>210.5</td>\n",
       "      <td>224.0</td>\n",
       "      <td>231.50</td>\n",
       "      <td>239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ambulance</th>\n",
       "      <td>12.0</td>\n",
       "      <td>275.083333</td>\n",
       "      <td>15.733337</td>\n",
       "      <td>250.0</td>\n",
       "      <td>258.5</td>\n",
       "      <td>280.0</td>\n",
       "      <td>286.50</td>\n",
       "      <td>295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wounded</th>\n",
       "      <td>13.0</td>\n",
       "      <td>10610.538462</td>\n",
       "      <td>15.365629</td>\n",
       "      <td>10586.0</td>\n",
       "      <td>10597.0</td>\n",
       "      <td>10614.0</td>\n",
       "      <td>10619.00</td>\n",
       "      <td>10634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wounds</th>\n",
       "      <td>17.0</td>\n",
       "      <td>10653.882353</td>\n",
       "      <td>13.972662</td>\n",
       "      <td>10635.0</td>\n",
       "      <td>10643.0</td>\n",
       "      <td>10652.0</td>\n",
       "      <td>10664.00</td>\n",
       "      <td>10683.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wreck</th>\n",
       "      <td>13.0</td>\n",
       "      <td>10712.307692</td>\n",
       "      <td>12.658229</td>\n",
       "      <td>10694.0</td>\n",
       "      <td>10701.0</td>\n",
       "      <td>10714.0</td>\n",
       "      <td>10719.00</td>\n",
       "      <td>10734.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wreckage</th>\n",
       "      <td>11.0</td>\n",
       "      <td>10758.727273</td>\n",
       "      <td>14.690752</td>\n",
       "      <td>10738.0</td>\n",
       "      <td>10749.0</td>\n",
       "      <td>10758.0</td>\n",
       "      <td>10767.50</td>\n",
       "      <td>10781.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrecked</th>\n",
       "      <td>11.0</td>\n",
       "      <td>10805.272727</td>\n",
       "      <td>11.858254</td>\n",
       "      <td>10791.0</td>\n",
       "      <td>10796.5</td>\n",
       "      <td>10804.0</td>\n",
       "      <td>10811.50</td>\n",
       "      <td>10828.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                                      \\\n",
       "                    count          mean        std      min      25%      50%   \n",
       "keyword                                                                         \n",
       "ablaze               14.0     70.785714  16.446550     46.0     58.5     71.0   \n",
       "accident             15.0    117.466667  13.211827     99.0    107.0    116.0   \n",
       "aftershock           16.0    168.750000  16.114176    147.0    153.5    168.0   \n",
       "airplane%20accident  15.0    221.333333  12.893335    200.0    210.5    224.0   \n",
       "ambulance            12.0    275.083333  15.733337    250.0    258.5    280.0   \n",
       "...                   ...           ...        ...      ...      ...      ...   \n",
       "wounded              13.0  10610.538462  15.365629  10586.0  10597.0  10614.0   \n",
       "wounds               17.0  10653.882353  13.972662  10635.0  10643.0  10652.0   \n",
       "wreck                13.0  10712.307692  12.658229  10694.0  10701.0  10714.0   \n",
       "wreckage             11.0  10758.727273  14.690752  10738.0  10749.0  10758.0   \n",
       "wrecked              11.0  10805.272727  11.858254  10791.0  10796.5  10804.0   \n",
       "\n",
       "                                        \n",
       "                          75%      max  \n",
       "keyword                                 \n",
       "ablaze                  86.25     94.0  \n",
       "accident               124.50    142.0  \n",
       "aftershock             182.25    192.0  \n",
       "airplane%20accident    231.50    239.0  \n",
       "ambulance              286.50    295.0  \n",
       "...                       ...      ...  \n",
       "wounded              10619.00  10634.0  \n",
       "wounds               10664.00  10683.0  \n",
       "wreck                10719.00  10734.0  \n",
       "wreckage             10767.50  10781.0  \n",
       "wrecked              10811.50  10828.0  \n",
       "\n",
       "[221 rows x 8 columns]"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.groupby([\"keyword\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword     target\n",
       "ablaze      0         23\n",
       "            1         13\n",
       "accident    0         11\n",
       "            1         24\n",
       "aftershock  0         34\n",
       "                      ..\n",
       "wreck       0         30\n",
       "            1          7\n",
       "wreckage    1         39\n",
       "wrecked     0         36\n",
       "            1          3\n",
       "Name: keyword, Length: 438, dtype: int64"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby([\"keyword\", \"target\"])[\"keyword\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill empty cell\n",
    "df_train = df_train.fillna(\"none\")\n",
    "df_test = df_test.fillna(\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1    none     none  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4    none     none             Forest fire near La Ronge Sask. Canada   \n",
       "2   5    none     none  All residents asked to 'shelter in place' are ...   \n",
       "3   6    none     none  13,000 people receive #wildfires evacuation or...   \n",
       "4   7    none     none  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat keywords and text\n",
    "df_train[\"text\"]  = 'keyword: ' + df_train[\"keyword\"] + ' - ' + df_train[\"text\"]\n",
    "df_test[\"text\"]  = 'keyword: ' + df_test[\"keyword\"] + ' - ' + df_test[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    html = re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text) # no emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'] = df_train['text'].apply(remove_url).apply(remove_html).apply(remove_emoji)\n",
    "df_test['text'] = df_test['text'].apply(remove_url).apply(remove_html).apply(remove_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>73</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Sheffield Township, Ohio</td>\n",
       "      <td>keyword: ablaze - Deputies: Man shot before Br...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>74</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>India</td>\n",
       "      <td>keyword: ablaze - Man wife get six years jail ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>76</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Barbados</td>\n",
       "      <td>keyword: ablaze - SANTA CRUZ ÛÓ Head of the S...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>77</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Anaheim</td>\n",
       "      <td>keyword: ablaze - Police: Arsonist Deliberatel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>78</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>keyword: ablaze - Noches El-Bestia '@Alexis_Sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>79</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>USA</td>\n",
       "      <td>keyword: ablaze - #Kurds trampling on Turkmen ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>80</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>keyword: ablaze - TRUCK ABLAZE : R21. VOORTREK...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>81</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Sao Paulo, Brazil</td>\n",
       "      <td>keyword: ablaze - Set our hearts ablaze and ev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>82</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>hollywoodland</td>\n",
       "      <td>keyword: ablaze - They sky was ablaze tonight ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>83</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Edmonton, Alberta - Treaty 6</td>\n",
       "      <td>keyword: ablaze - How the West was burned: Tho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>85</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>none</td>\n",
       "      <td>keyword: ablaze - Revel in yours wmv videos by...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>86</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Inang Pamantasan</td>\n",
       "      <td>keyword: ablaze - Progressive greetings!\\n\\nIn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>89</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Twitter Lockout in progress</td>\n",
       "      <td>keyword: ablaze - Rene Ablaze &amp;amp; Jacinta - ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>91</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Concord, CA</td>\n",
       "      <td>keyword: ablaze - @Navista7 Steve these fires ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>92</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Calgary, AB</td>\n",
       "      <td>keyword: ablaze - #NowPlaying: Rene Ablaze &amp;am...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>93</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>keyword: ablaze - @nxwestmidlands huge fire at...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>95</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>keyword: ablaze - @ablaze what time does your ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>96</td>\n",
       "      <td>accident</td>\n",
       "      <td>CLVLND</td>\n",
       "      <td>keyword: accident - 'I can't have kids cuz I g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>97</td>\n",
       "      <td>accident</td>\n",
       "      <td>Nashville, TN</td>\n",
       "      <td>keyword: accident - Accident on I-24 W #Nashvi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>98</td>\n",
       "      <td>accident</td>\n",
       "      <td>Santa Clara, CA</td>\n",
       "      <td>keyword: accident - Accident center lane block...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id   keyword                      location  \\\n",
       "50  73    ablaze      Sheffield Township, Ohio   \n",
       "51  74    ablaze                         India   \n",
       "52  76    ablaze                      Barbados   \n",
       "53  77    ablaze                       Anaheim   \n",
       "54  78    ablaze                         Abuja   \n",
       "55  79    ablaze                           USA   \n",
       "56  80    ablaze                  South Africa   \n",
       "57  81    ablaze             Sao Paulo, Brazil   \n",
       "58  82    ablaze                hollywoodland    \n",
       "59  83    ablaze  Edmonton, Alberta - Treaty 6   \n",
       "60  85    ablaze                          none   \n",
       "61  86    ablaze              Inang Pamantasan   \n",
       "62  89    ablaze   Twitter Lockout in progress   \n",
       "63  91    ablaze                   Concord, CA   \n",
       "64  92    ablaze                   Calgary, AB   \n",
       "65  93    ablaze                    Birmingham   \n",
       "66  95    ablaze                 San Francisco   \n",
       "67  96  accident                        CLVLND   \n",
       "68  97  accident                 Nashville, TN   \n",
       "69  98  accident               Santa Clara, CA   \n",
       "\n",
       "                                                 text  target  \n",
       "50  keyword: ablaze - Deputies: Man shot before Br...       1  \n",
       "51  keyword: ablaze - Man wife get six years jail ...       1  \n",
       "52  keyword: ablaze - SANTA CRUZ ÛÓ Head of the S...       0  \n",
       "53  keyword: ablaze - Police: Arsonist Deliberatel...       1  \n",
       "54  keyword: ablaze - Noches El-Bestia '@Alexis_Sa...       0  \n",
       "55  keyword: ablaze - #Kurds trampling on Turkmen ...       1  \n",
       "56  keyword: ablaze - TRUCK ABLAZE : R21. VOORTREK...       1  \n",
       "57  keyword: ablaze - Set our hearts ablaze and ev...       0  \n",
       "58  keyword: ablaze - They sky was ablaze tonight ...       0  \n",
       "59  keyword: ablaze - How the West was burned: Tho...       1  \n",
       "60  keyword: ablaze - Revel in yours wmv videos by...       0  \n",
       "61  keyword: ablaze - Progressive greetings!\\n\\nIn...       0  \n",
       "62  keyword: ablaze - Rene Ablaze &amp; Jacinta - ...       0  \n",
       "63  keyword: ablaze - @Navista7 Steve these fires ...       1  \n",
       "64  keyword: ablaze - #NowPlaying: Rene Ablaze &am...       0  \n",
       "65  keyword: ablaze - @nxwestmidlands huge fire at...       1  \n",
       "66  keyword: ablaze - @ablaze what time does your ...       0  \n",
       "67  keyword: accident - 'I can't have kids cuz I g...       0  \n",
       "68  keyword: accident - Accident on I-24 W #Nashvi...       1  \n",
       "69  keyword: accident - Accident center lane block...       1  "
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[50:70,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Length Stat\n",
      "count    7613.000000\n",
      "mean      108.022068\n",
      "std        33.249476\n",
      "min        24.000000\n",
      "25%        83.000000\n",
      "50%       110.000000\n",
      "75%       135.000000\n",
      "max       175.000000\n",
      "Name: length, dtype: float64\n",
      "\n",
      "Test Length Stat\n",
      "count    3263.000000\n",
      "mean      109.040147\n",
      "std        33.442043\n",
      "min        22.000000\n",
      "25%        84.000000\n",
      "50%       112.000000\n",
      "75%       135.500000\n",
      "max       182.000000\n",
      "Name: length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_train[\"length\"] = df_train[\"text\"].apply(lambda x : len(x))\n",
    "df_test[\"length\"] = df_test[\"text\"].apply(lambda x : len(x))\n",
    "\n",
    "print(\"Train Length Stat\")\n",
    "print(df_train[\"length\"].describe())\n",
    "print()\n",
    "\n",
    "print(\"Test Length Stat\")\n",
    "print(df_test[\"length\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = df_train[\"target\"]\n",
    "plt.hist(labels)\n",
    "plt.xlabel('target')\n",
    "plt.ylabel('nb samples')\n",
    "plt.title('target distribution')\n",
    "plt.xticks(np.arange(len(np.unique(labels))));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Pre-trained BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_transform', 'vocab_layer_norm', 'vocab_projector']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.TFDistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "distilbert (TFDistilBertMain multiple                  66362880  \n",
      "=================================================================\n",
      "Total params: 66,362,880\n",
      "Trainable params: 66,362,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences):\n",
    "    tokenized = [tokenizer(sentence, add_special_tokens=True)['input_ids'] for sentence in sentences]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenize(df_train[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence:  keyword: none - Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
      "tokenized:  [101, 3145, 18351, 1024, 3904, 1011, 2256, 15616, 2024, 1996, 3114, 1997, 2023, 1001, 8372, 2089, 16455, 9641, 2149, 2035, 102]\n",
      "decoded:  [CLS] keyword : none - our deeds are the reason of this # earthquake may allah forgive us all [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(\"sentence: \", df_train[\"text\"][0] )\n",
    "print(\"tokenized: \", tokenized[0])\n",
    "print(\"decoded: \", tokenizer.decode(tokenized[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length is  182\n"
     ]
    }
   ],
   "source": [
    "# get the maxh length\n",
    "max_len = max(df_train[\"length\"].max(), df_test[\"length\"].max())\n",
    "print(\"Max sentence length is \", max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tokens(tokens, max_len):\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokens])\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  101  3145 18351  1024  3904  1011  2256 15616  2024  1996  3114  1997\n",
      "  2023  1001  8372  2089 16455  9641  2149  2035   102     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0]\n"
     ]
    }
   ],
   "source": [
    "padded = pad_tokens(tokenized, max_len)\n",
    "print(padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of padded:  (7613, 182)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of padded: \", padded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_mask(tokens):\n",
    "    attention_mask = np.where(tokens != 0, 1, 0)    \n",
    "    return attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "attention_mask = get_attention_mask(padded)\n",
    "print(attention_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of attention mask:  (7613, 182)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of attention mask: \", attention_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.convert_to_tensor(padded, dtype=tf.int32)\n",
    "attention_mask = tf.convert_to_tensor(attention_mask, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract feature vectors\n",
    "The model() function runs our sentences through BERT. The results of the processing will be returned into last_hidden_states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(input_ids, attention_mask):\n",
    "    batch_size = 200\n",
    "    m = input_ids.shape[0]\n",
    "    n = int(m / batch_size)\n",
    "\n",
    "    hidden_units =  model.config.to_dict()['dim']\n",
    "    features = np.zeros((m, hidden_units))\n",
    "\n",
    "    print('Extract features using batches for memory issue:')\n",
    "\n",
    "    for i in range(n):\n",
    "        j, k = i*batch_size, i*batch_size+batch_size\n",
    "        print(f'Batch {i+1} [{j}:{k}]')\n",
    "        batch_input = input_ids[j:k]\n",
    "        batch_attention_mask = attention_mask[j:k]\n",
    "        last_hidden_states = model(batch_input, attention_mask = batch_attention_mask)\n",
    "\n",
    "        # Let's slice only the part of the output that we need. That is the output corresponding the first token of each sentence. \n",
    "        # The way BERT does sentence classification, is that it adds a token called [CLS] (for classification) at the beginning of \n",
    "        # every sentence. The output corresponding to that token can be thought of as an embedding for the entire sentence.\n",
    "        features[j:k] = last_hidden_states[0][:,0,:].numpy()\n",
    "\n",
    "        ## if you use BERT instead of distilBERT model, use this\n",
    "        #features[j:k] = last_hidden_states[1].numpy() \n",
    "\n",
    "    if(n*batch_size != m):\n",
    "        i = i + 1\n",
    "        j, k = i*batch_size, i*batch_size+(m-n*batch_size)\n",
    "        print(f'Batch {i+1} [{j}:{k}]')\n",
    "        batch_input = input_ids[j:k]\n",
    "        batch_attention_mask = attention_mask[j:k]\n",
    "        last_hidden_states = model(batch_input, attention_mask = batch_attention_mask)\n",
    "        features[j:k] = last_hidden_states[0][:,0,:].numpy()\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(input_ids, attention_mask, filename):\n",
    "    if os.path.exists(filename):\n",
    "        F = np.load(filename)\n",
    "    else:\n",
    "        F = extract_features(input_ids, attention_mask)\n",
    "        np.save(filename, F)\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature vectors:  (7613, 768)\n"
     ]
    }
   ],
   "source": [
    "features = get_features(input_ids, attention_mask, \"data/E3_train.npy\")\n",
    "print(\"shape of feature vectors: \", features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature labels:  (7613,)\n"
     ]
    }
   ],
   "source": [
    "lables = df_train[\"target\"].to_numpy()\n",
    "print(\"shape of feature labels: \", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of training data:  (7536, 768) (7536,)\n",
      "shapes of validation data:  (77, 768) (77,)\n"
     ]
    }
   ],
   "source": [
    "# 80% train, 20% validation\n",
    "split_size = int(features.shape[0] * .99)    \n",
    "X_train = features[:split_size,:]\n",
    "Y_train = lables[:split_size]\n",
    "X_val = features[split_size:,:]\n",
    "Y_val = lables[split_size:]\n",
    "\n",
    "print(\"shapes of training data: \", X_train.shape, Y_train.shape)\n",
    "print(\"shapes of validation data: \", X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, classes):\n",
    "    inputs = keras.Input(shape=input_shape, name='input')\n",
    "    outputs = keras.layers.Dense(classes, activation='sigmoid', name='output')(inputs)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adamax()\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=optimizer, \n",
    "        metrics=['binary_accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 768)]             0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 769       \n",
      "=================================================================\n",
      "Total params: 769\n",
      "Trainable params: 769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lr_model = create_model(X_train.shape[1], 1)\n",
    "lr_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 833,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(lr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "56/56 [==============================] - 1s 3ms/step - loss: 0.6442 - binary_accuracy: 0.6462 - val_loss: 0.6053 - val_binary_accuracy: 0.7613\n",
      "Epoch 2/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.5727 - binary_accuracy: 0.7540 - val_loss: 0.5535 - val_binary_accuracy: 0.7666\n",
      "Epoch 3/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.5347 - binary_accuracy: 0.7741 - val_loss: 0.5205 - val_binary_accuracy: 0.7692\n",
      "Epoch 4/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.5111 - binary_accuracy: 0.7808 - val_loss: 0.4955 - val_binary_accuracy: 0.7798\n",
      "Epoch 5/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4953 - binary_accuracy: 0.7824 - val_loss: 0.4801 - val_binary_accuracy: 0.7772\n",
      "Epoch 6/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4842 - binary_accuracy: 0.7882 - val_loss: 0.4750 - val_binary_accuracy: 0.7798\n",
      "Epoch 7/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4751 - binary_accuracy: 0.7919 - val_loss: 0.4674 - val_binary_accuracy: 0.7798\n",
      "Epoch 8/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4680 - binary_accuracy: 0.7931 - val_loss: 0.4590 - val_binary_accuracy: 0.7825\n",
      "Epoch 9/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4617 - binary_accuracy: 0.7970 - val_loss: 0.4524 - val_binary_accuracy: 0.7905\n",
      "Epoch 10/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4571 - binary_accuracy: 0.7973 - val_loss: 0.4502 - val_binary_accuracy: 0.7878\n",
      "Epoch 11/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4524 - binary_accuracy: 0.8009 - val_loss: 0.4462 - val_binary_accuracy: 0.7931\n",
      "Epoch 12/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4484 - binary_accuracy: 0.8021 - val_loss: 0.4507 - val_binary_accuracy: 0.7984\n",
      "Epoch 13/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4464 - binary_accuracy: 0.8019 - val_loss: 0.4402 - val_binary_accuracy: 0.7958\n",
      "Epoch 14/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4427 - binary_accuracy: 0.8035 - val_loss: 0.4387 - val_binary_accuracy: 0.7984\n",
      "Epoch 15/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4405 - binary_accuracy: 0.8061 - val_loss: 0.4375 - val_binary_accuracy: 0.8011\n",
      "Epoch 16/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4383 - binary_accuracy: 0.8049 - val_loss: 0.4350 - val_binary_accuracy: 0.8011\n",
      "Epoch 17/400\n",
      "43/56 [======================>.......] - ETA: 0s - loss: 0.4352 - binary_accuracy: 0.8063"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4361 - binary_accuracy: 0.8051 - val_loss: 0.4320 - val_binary_accuracy: 0.7931\n",
      "Epoch 18/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4341 - binary_accuracy: 0.8053 - val_loss: 0.4310 - val_binary_accuracy: 0.8064\n",
      "Epoch 19/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4328 - binary_accuracy: 0.8096 - val_loss: 0.4298 - val_binary_accuracy: 0.8037\n",
      "Epoch 20/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4311 - binary_accuracy: 0.8081 - val_loss: 0.4307 - val_binary_accuracy: 0.8037\n",
      "Epoch 21/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4296 - binary_accuracy: 0.8088 - val_loss: 0.4248 - val_binary_accuracy: 0.7958\n",
      "Epoch 22/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4290 - binary_accuracy: 0.8093 - val_loss: 0.4250 - val_binary_accuracy: 0.7984\n",
      "Epoch 23/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4278 - binary_accuracy: 0.8097 - val_loss: 0.4254 - val_binary_accuracy: 0.7958\n",
      "Epoch 24/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4268 - binary_accuracy: 0.8099 - val_loss: 0.4225 - val_binary_accuracy: 0.8011\n",
      "Epoch 25/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4254 - binary_accuracy: 0.8107 - val_loss: 0.4244 - val_binary_accuracy: 0.8037\n",
      "Epoch 26/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4244 - binary_accuracy: 0.8118 - val_loss: 0.4255 - val_binary_accuracy: 0.7984\n",
      "Epoch 27/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4235 - binary_accuracy: 0.8137 - val_loss: 0.4260 - val_binary_accuracy: 0.8064\n",
      "Epoch 28/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4227 - binary_accuracy: 0.8117 - val_loss: 0.4213 - val_binary_accuracy: 0.8037\n",
      "Epoch 29/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4217 - binary_accuracy: 0.8137 - val_loss: 0.4226 - val_binary_accuracy: 0.8064\n",
      "Epoch 30/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4214 - binary_accuracy: 0.8127 - val_loss: 0.4209 - val_binary_accuracy: 0.8011\n",
      "Epoch 31/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4206 - binary_accuracy: 0.8127 - val_loss: 0.4200 - val_binary_accuracy: 0.8011\n",
      "Epoch 32/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4197 - binary_accuracy: 0.8155 - val_loss: 0.4199 - val_binary_accuracy: 0.8064\n",
      "Epoch 33/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4188 - binary_accuracy: 0.8144 - val_loss: 0.4240 - val_binary_accuracy: 0.8090\n",
      "Epoch 34/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4188 - binary_accuracy: 0.8123 - val_loss: 0.4192 - val_binary_accuracy: 0.8090\n",
      "Epoch 35/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4184 - binary_accuracy: 0.8142 - val_loss: 0.4217 - val_binary_accuracy: 0.8117\n",
      "Epoch 36/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4172 - binary_accuracy: 0.8144 - val_loss: 0.4177 - val_binary_accuracy: 0.8064\n",
      "Epoch 37/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4175 - binary_accuracy: 0.8158 - val_loss: 0.4230 - val_binary_accuracy: 0.8143\n",
      "Epoch 38/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4169 - binary_accuracy: 0.8145 - val_loss: 0.4203 - val_binary_accuracy: 0.8117\n",
      "Epoch 39/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4156 - binary_accuracy: 0.8167 - val_loss: 0.4200 - val_binary_accuracy: 0.8117\n",
      "Epoch 40/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4154 - binary_accuracy: 0.8176 - val_loss: 0.4195 - val_binary_accuracy: 0.8143\n",
      "Epoch 41/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4152 - binary_accuracy: 0.8163 - val_loss: 0.4210 - val_binary_accuracy: 0.8143\n",
      "Epoch 42/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4140 - binary_accuracy: 0.8172 - val_loss: 0.4163 - val_binary_accuracy: 0.8117\n",
      "Epoch 43/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4140 - binary_accuracy: 0.8176 - val_loss: 0.4226 - val_binary_accuracy: 0.8143\n",
      "Epoch 44/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4136 - binary_accuracy: 0.8169 - val_loss: 0.4170 - val_binary_accuracy: 0.8170\n",
      "Epoch 45/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4130 - binary_accuracy: 0.8170 - val_loss: 0.4241 - val_binary_accuracy: 0.8170\n",
      "Epoch 46/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4126 - binary_accuracy: 0.8177 - val_loss: 0.4177 - val_binary_accuracy: 0.8196\n",
      "Epoch 47/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4120 - binary_accuracy: 0.8177 - val_loss: 0.4163 - val_binary_accuracy: 0.8170\n",
      "Epoch 48/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4121 - binary_accuracy: 0.8192 - val_loss: 0.4207 - val_binary_accuracy: 0.8170\n",
      "Epoch 49/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4117 - binary_accuracy: 0.8180 - val_loss: 0.4180 - val_binary_accuracy: 0.8223\n",
      "Epoch 50/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4108 - binary_accuracy: 0.8191 - val_loss: 0.4180 - val_binary_accuracy: 0.8223\n",
      "Epoch 51/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4107 - binary_accuracy: 0.8194 - val_loss: 0.4184 - val_binary_accuracy: 0.8223\n",
      "Epoch 52/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4104 - binary_accuracy: 0.8201 - val_loss: 0.4155 - val_binary_accuracy: 0.8170\n",
      "Epoch 53/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4102 - binary_accuracy: 0.8191 - val_loss: 0.4156 - val_binary_accuracy: 0.8170\n",
      "Epoch 54/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4099 - binary_accuracy: 0.8184 - val_loss: 0.4190 - val_binary_accuracy: 0.8249\n",
      "Epoch 55/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4091 - binary_accuracy: 0.8176 - val_loss: 0.4140 - val_binary_accuracy: 0.8143\n",
      "Epoch 56/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4093 - binary_accuracy: 0.8198 - val_loss: 0.4160 - val_binary_accuracy: 0.8196\n",
      "Epoch 57/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4088 - binary_accuracy: 0.8199 - val_loss: 0.4155 - val_binary_accuracy: 0.8170\n",
      "Epoch 58/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4083 - binary_accuracy: 0.8213 - val_loss: 0.4155 - val_binary_accuracy: 0.8196\n",
      "Epoch 59/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4084 - binary_accuracy: 0.8179 - val_loss: 0.4187 - val_binary_accuracy: 0.8249\n",
      "Epoch 60/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4082 - binary_accuracy: 0.8192 - val_loss: 0.4171 - val_binary_accuracy: 0.8249\n",
      "Epoch 61/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4080 - binary_accuracy: 0.8192 - val_loss: 0.4182 - val_binary_accuracy: 0.8249\n",
      "Epoch 62/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4076 - binary_accuracy: 0.8202 - val_loss: 0.4165 - val_binary_accuracy: 0.8249\n",
      "Epoch 63/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4071 - binary_accuracy: 0.8198 - val_loss: 0.4146 - val_binary_accuracy: 0.8170\n",
      "Epoch 64/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4069 - binary_accuracy: 0.8211 - val_loss: 0.4152 - val_binary_accuracy: 0.8196\n",
      "Epoch 65/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4065 - binary_accuracy: 0.8223 - val_loss: 0.4142 - val_binary_accuracy: 0.8170\n",
      "Epoch 66/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4065 - binary_accuracy: 0.8198 - val_loss: 0.4150 - val_binary_accuracy: 0.8223\n",
      "Epoch 67/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4062 - binary_accuracy: 0.8209 - val_loss: 0.4163 - val_binary_accuracy: 0.8223\n",
      "Epoch 68/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4063 - binary_accuracy: 0.8198 - val_loss: 0.4142 - val_binary_accuracy: 0.8196\n",
      "Epoch 69/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4057 - binary_accuracy: 0.8227 - val_loss: 0.4168 - val_binary_accuracy: 0.8249\n",
      "Epoch 70/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4051 - binary_accuracy: 0.8227 - val_loss: 0.4142 - val_binary_accuracy: 0.8223\n",
      "Epoch 71/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4053 - binary_accuracy: 0.8213 - val_loss: 0.4133 - val_binary_accuracy: 0.8117\n",
      "Epoch 72/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4050 - binary_accuracy: 0.8232 - val_loss: 0.4128 - val_binary_accuracy: 0.8117\n",
      "Epoch 73/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4051 - binary_accuracy: 0.8226 - val_loss: 0.4126 - val_binary_accuracy: 0.8117\n",
      "Epoch 74/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4049 - binary_accuracy: 0.8205 - val_loss: 0.4151 - val_binary_accuracy: 0.8223\n",
      "Epoch 75/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4043 - binary_accuracy: 0.8216 - val_loss: 0.4162 - val_binary_accuracy: 0.8276\n",
      "Epoch 76/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4037 - binary_accuracy: 0.8218 - val_loss: 0.4120 - val_binary_accuracy: 0.8090\n",
      "Epoch 77/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4037 - binary_accuracy: 0.8204 - val_loss: 0.4153 - val_binary_accuracy: 0.8223\n",
      "Epoch 78/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4033 - binary_accuracy: 0.8218 - val_loss: 0.4175 - val_binary_accuracy: 0.8276\n",
      "Epoch 79/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4035 - binary_accuracy: 0.8220 - val_loss: 0.4116 - val_binary_accuracy: 0.8090\n",
      "Epoch 80/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4031 - binary_accuracy: 0.8206 - val_loss: 0.4166 - val_binary_accuracy: 0.8276\n",
      "Epoch 81/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4028 - binary_accuracy: 0.8241 - val_loss: 0.4147 - val_binary_accuracy: 0.8223\n",
      "Epoch 82/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4028 - binary_accuracy: 0.8209 - val_loss: 0.4137 - val_binary_accuracy: 0.8196\n",
      "Epoch 83/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4026 - binary_accuracy: 0.8233 - val_loss: 0.4145 - val_binary_accuracy: 0.8249\n",
      "Epoch 84/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4023 - binary_accuracy: 0.8241 - val_loss: 0.4113 - val_binary_accuracy: 0.8090\n",
      "Epoch 85/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4022 - binary_accuracy: 0.8223 - val_loss: 0.4189 - val_binary_accuracy: 0.8223\n",
      "Epoch 86/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4027 - binary_accuracy: 0.8233 - val_loss: 0.4140 - val_binary_accuracy: 0.8196\n",
      "Epoch 87/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4023 - binary_accuracy: 0.8233 - val_loss: 0.4132 - val_binary_accuracy: 0.8170\n",
      "Epoch 88/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4016 - binary_accuracy: 0.8234 - val_loss: 0.4116 - val_binary_accuracy: 0.8143\n",
      "Epoch 89/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4019 - binary_accuracy: 0.8222 - val_loss: 0.4137 - val_binary_accuracy: 0.8223\n",
      "Epoch 90/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4013 - binary_accuracy: 0.8254 - val_loss: 0.4132 - val_binary_accuracy: 0.8196\n",
      "Epoch 91/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4009 - binary_accuracy: 0.8247 - val_loss: 0.4130 - val_binary_accuracy: 0.8143\n",
      "Epoch 92/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4015 - binary_accuracy: 0.8253 - val_loss: 0.4120 - val_binary_accuracy: 0.8143\n",
      "Epoch 93/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4009 - binary_accuracy: 0.8240 - val_loss: 0.4110 - val_binary_accuracy: 0.8143\n",
      "Epoch 94/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4008 - binary_accuracy: 0.8250 - val_loss: 0.4121 - val_binary_accuracy: 0.8143\n",
      "Epoch 95/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4003 - binary_accuracy: 0.8254 - val_loss: 0.4136 - val_binary_accuracy: 0.8223\n",
      "Epoch 96/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.4007 - binary_accuracy: 0.8246 - val_loss: 0.4120 - val_binary_accuracy: 0.8143\n",
      "Epoch 97/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.4007 - binary_accuracy: 0.8246 - val_loss: 0.4132 - val_binary_accuracy: 0.8196\n",
      "Epoch 98/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3999 - binary_accuracy: 0.8255 - val_loss: 0.4110 - val_binary_accuracy: 0.8117\n",
      "Epoch 99/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3998 - binary_accuracy: 0.8247 - val_loss: 0.4107 - val_binary_accuracy: 0.8143\n",
      "Epoch 100/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3994 - binary_accuracy: 0.8260 - val_loss: 0.4181 - val_binary_accuracy: 0.8223\n",
      "Epoch 101/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3996 - binary_accuracy: 0.8267 - val_loss: 0.4103 - val_binary_accuracy: 0.8143\n",
      "Epoch 102/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3993 - binary_accuracy: 0.8250 - val_loss: 0.4121 - val_binary_accuracy: 0.8170\n",
      "Epoch 103/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3991 - binary_accuracy: 0.8268 - val_loss: 0.4126 - val_binary_accuracy: 0.8196\n",
      "Epoch 104/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3991 - binary_accuracy: 0.8278 - val_loss: 0.4126 - val_binary_accuracy: 0.8170\n",
      "Epoch 105/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3988 - binary_accuracy: 0.8261 - val_loss: 0.4129 - val_binary_accuracy: 0.8196\n",
      "Epoch 106/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3982 - binary_accuracy: 0.8271 - val_loss: 0.4091 - val_binary_accuracy: 0.8143\n",
      "Epoch 107/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3989 - binary_accuracy: 0.8261 - val_loss: 0.4123 - val_binary_accuracy: 0.8170\n",
      "Epoch 108/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3985 - binary_accuracy: 0.8253 - val_loss: 0.4097 - val_binary_accuracy: 0.8117\n",
      "Epoch 109/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3981 - binary_accuracy: 0.8271 - val_loss: 0.4128 - val_binary_accuracy: 0.8196\n",
      "Epoch 110/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3978 - binary_accuracy: 0.8268 - val_loss: 0.4147 - val_binary_accuracy: 0.8196\n",
      "Epoch 111/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3979 - binary_accuracy: 0.8254 - val_loss: 0.4105 - val_binary_accuracy: 0.8117\n",
      "Epoch 112/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3978 - binary_accuracy: 0.8267 - val_loss: 0.4110 - val_binary_accuracy: 0.8143\n",
      "Epoch 113/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3975 - binary_accuracy: 0.8271 - val_loss: 0.4094 - val_binary_accuracy: 0.8170\n",
      "Epoch 114/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3977 - binary_accuracy: 0.8253 - val_loss: 0.4147 - val_binary_accuracy: 0.8196\n",
      "Epoch 115/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3980 - binary_accuracy: 0.8246 - val_loss: 0.4132 - val_binary_accuracy: 0.8196\n",
      "Epoch 116/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3971 - binary_accuracy: 0.8278 - val_loss: 0.4103 - val_binary_accuracy: 0.8143\n",
      "Epoch 117/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3976 - binary_accuracy: 0.8272 - val_loss: 0.4099 - val_binary_accuracy: 0.8117\n",
      "Epoch 118/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3970 - binary_accuracy: 0.8272 - val_loss: 0.4086 - val_binary_accuracy: 0.8196\n",
      "Epoch 119/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3972 - binary_accuracy: 0.8255 - val_loss: 0.4086 - val_binary_accuracy: 0.8170\n",
      "Epoch 120/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3969 - binary_accuracy: 0.8272 - val_loss: 0.4148 - val_binary_accuracy: 0.8196\n",
      "Epoch 121/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3972 - binary_accuracy: 0.8265 - val_loss: 0.4118 - val_binary_accuracy: 0.8143\n",
      "Epoch 122/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3967 - binary_accuracy: 0.8280 - val_loss: 0.4122 - val_binary_accuracy: 0.8170\n",
      "Epoch 123/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3962 - binary_accuracy: 0.8271 - val_loss: 0.4112 - val_binary_accuracy: 0.8170\n",
      "Epoch 124/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3962 - binary_accuracy: 0.8267 - val_loss: 0.4122 - val_binary_accuracy: 0.8170\n",
      "Epoch 125/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3961 - binary_accuracy: 0.8278 - val_loss: 0.4112 - val_binary_accuracy: 0.8170\n",
      "Epoch 126/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3959 - binary_accuracy: 0.8271 - val_loss: 0.4114 - val_binary_accuracy: 0.8170\n",
      "Epoch 127/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3958 - binary_accuracy: 0.8279 - val_loss: 0.4101 - val_binary_accuracy: 0.8143\n",
      "Epoch 128/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3961 - binary_accuracy: 0.8275 - val_loss: 0.4098 - val_binary_accuracy: 0.8143\n",
      "Epoch 129/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3957 - binary_accuracy: 0.8269 - val_loss: 0.4129 - val_binary_accuracy: 0.8170\n",
      "Epoch 130/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3964 - binary_accuracy: 0.8271 - val_loss: 0.4089 - val_binary_accuracy: 0.8170\n",
      "Epoch 131/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3956 - binary_accuracy: 0.8265 - val_loss: 0.4103 - val_binary_accuracy: 0.8143\n",
      "Epoch 132/400\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.3956 - binary_accuracy: 0.8274 - val_loss: 0.4118 - val_binary_accuracy: 0.8143\n",
      "Epoch 133/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3954 - binary_accuracy: 0.8269 - val_loss: 0.4104 - val_binary_accuracy: 0.8143\n",
      "Epoch 134/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3948 - binary_accuracy: 0.8271 - val_loss: 0.4082 - val_binary_accuracy: 0.8223\n",
      "Epoch 135/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3949 - binary_accuracy: 0.8275 - val_loss: 0.4111 - val_binary_accuracy: 0.8143\n",
      "Epoch 136/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3943 - binary_accuracy: 0.8279 - val_loss: 0.4087 - val_binary_accuracy: 0.8170\n",
      "Epoch 137/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3946 - binary_accuracy: 0.8271 - val_loss: 0.4078 - val_binary_accuracy: 0.8249\n",
      "Epoch 138/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3950 - binary_accuracy: 0.8280 - val_loss: 0.4087 - val_binary_accuracy: 0.8223\n",
      "Epoch 139/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3949 - binary_accuracy: 0.8279 - val_loss: 0.4109 - val_binary_accuracy: 0.8143\n",
      "Epoch 140/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3943 - binary_accuracy: 0.8275 - val_loss: 0.4092 - val_binary_accuracy: 0.8170\n",
      "Epoch 141/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3945 - binary_accuracy: 0.8283 - val_loss: 0.4093 - val_binary_accuracy: 0.8170\n",
      "Epoch 142/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3939 - binary_accuracy: 0.8283 - val_loss: 0.4091 - val_binary_accuracy: 0.8170\n",
      "Epoch 143/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3942 - binary_accuracy: 0.8264 - val_loss: 0.4094 - val_binary_accuracy: 0.8196\n",
      "Epoch 144/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3939 - binary_accuracy: 0.8278 - val_loss: 0.4083 - val_binary_accuracy: 0.8249\n",
      "Epoch 145/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3943 - binary_accuracy: 0.8274 - val_loss: 0.4095 - val_binary_accuracy: 0.8143\n",
      "Epoch 146/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3934 - binary_accuracy: 0.8269 - val_loss: 0.4088 - val_binary_accuracy: 0.8223\n",
      "Epoch 147/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3932 - binary_accuracy: 0.8289 - val_loss: 0.4109 - val_binary_accuracy: 0.8143\n",
      "Epoch 148/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3935 - binary_accuracy: 0.8289 - val_loss: 0.4114 - val_binary_accuracy: 0.8143\n",
      "Epoch 149/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3933 - binary_accuracy: 0.8275 - val_loss: 0.4147 - val_binary_accuracy: 0.8196\n",
      "Epoch 150/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3929 - binary_accuracy: 0.8285 - val_loss: 0.4083 - val_binary_accuracy: 0.8249\n",
      "Epoch 151/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3930 - binary_accuracy: 0.8285 - val_loss: 0.4116 - val_binary_accuracy: 0.8143\n",
      "Epoch 152/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3929 - binary_accuracy: 0.8271 - val_loss: 0.4104 - val_binary_accuracy: 0.8117\n",
      "Epoch 153/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3928 - binary_accuracy: 0.8276 - val_loss: 0.4105 - val_binary_accuracy: 0.8117\n",
      "Epoch 154/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3927 - binary_accuracy: 0.8294 - val_loss: 0.4096 - val_binary_accuracy: 0.8117\n",
      "Epoch 155/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3931 - binary_accuracy: 0.8303 - val_loss: 0.4100 - val_binary_accuracy: 0.8117\n",
      "Epoch 156/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3927 - binary_accuracy: 0.8285 - val_loss: 0.4122 - val_binary_accuracy: 0.8170\n",
      "Epoch 157/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3921 - binary_accuracy: 0.8293 - val_loss: 0.4088 - val_binary_accuracy: 0.8223\n",
      "Epoch 158/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3922 - binary_accuracy: 0.8296 - val_loss: 0.4093 - val_binary_accuracy: 0.8223\n",
      "Epoch 159/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3922 - binary_accuracy: 0.8278 - val_loss: 0.4125 - val_binary_accuracy: 0.8170\n",
      "Epoch 160/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3922 - binary_accuracy: 0.8285 - val_loss: 0.4118 - val_binary_accuracy: 0.8170\n",
      "Epoch 161/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3920 - binary_accuracy: 0.8289 - val_loss: 0.4164 - val_binary_accuracy: 0.8223\n",
      "Epoch 162/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3921 - binary_accuracy: 0.8283 - val_loss: 0.4137 - val_binary_accuracy: 0.8170\n",
      "Epoch 163/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3924 - binary_accuracy: 0.8290 - val_loss: 0.4104 - val_binary_accuracy: 0.8117\n",
      "Epoch 164/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3917 - binary_accuracy: 0.8283 - val_loss: 0.4098 - val_binary_accuracy: 0.8143\n",
      "Epoch 165/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3915 - binary_accuracy: 0.8300 - val_loss: 0.4140 - val_binary_accuracy: 0.8170\n",
      "Epoch 166/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3919 - binary_accuracy: 0.8289 - val_loss: 0.4102 - val_binary_accuracy: 0.8143\n",
      "Epoch 167/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3915 - binary_accuracy: 0.8293 - val_loss: 0.4150 - val_binary_accuracy: 0.8196\n",
      "Epoch 168/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3917 - binary_accuracy: 0.8300 - val_loss: 0.4149 - val_binary_accuracy: 0.8196\n",
      "Epoch 169/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3915 - binary_accuracy: 0.8296 - val_loss: 0.4149 - val_binary_accuracy: 0.8196\n",
      "Epoch 170/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3921 - binary_accuracy: 0.8282 - val_loss: 0.4088 - val_binary_accuracy: 0.8223\n",
      "Epoch 171/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3912 - binary_accuracy: 0.8290 - val_loss: 0.4100 - val_binary_accuracy: 0.8170\n",
      "Epoch 172/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3908 - binary_accuracy: 0.8290 - val_loss: 0.4101 - val_binary_accuracy: 0.8170\n",
      "Epoch 173/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3907 - binary_accuracy: 0.8300 - val_loss: 0.4089 - val_binary_accuracy: 0.8196\n",
      "Epoch 174/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3908 - binary_accuracy: 0.8303 - val_loss: 0.4105 - val_binary_accuracy: 0.8117\n",
      "Epoch 175/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3908 - binary_accuracy: 0.8304 - val_loss: 0.4088 - val_binary_accuracy: 0.8223\n",
      "Epoch 176/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3907 - binary_accuracy: 0.8297 - val_loss: 0.4095 - val_binary_accuracy: 0.8196\n",
      "Epoch 177/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3906 - binary_accuracy: 0.8313 - val_loss: 0.4106 - val_binary_accuracy: 0.8170\n",
      "Epoch 178/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3904 - binary_accuracy: 0.8300 - val_loss: 0.4089 - val_binary_accuracy: 0.8223\n",
      "Epoch 179/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3904 - binary_accuracy: 0.8290 - val_loss: 0.4133 - val_binary_accuracy: 0.8170\n",
      "Epoch 180/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3906 - binary_accuracy: 0.8297 - val_loss: 0.4091 - val_binary_accuracy: 0.8196\n",
      "Epoch 181/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3905 - binary_accuracy: 0.8283 - val_loss: 0.4128 - val_binary_accuracy: 0.8170\n",
      "Epoch 182/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3902 - binary_accuracy: 0.8297 - val_loss: 0.4103 - val_binary_accuracy: 0.8170\n",
      "Epoch 183/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3902 - binary_accuracy: 0.8306 - val_loss: 0.4126 - val_binary_accuracy: 0.8170\n",
      "Epoch 184/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3899 - binary_accuracy: 0.8304 - val_loss: 0.4082 - val_binary_accuracy: 0.8249\n",
      "Epoch 185/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3900 - binary_accuracy: 0.8293 - val_loss: 0.4109 - val_binary_accuracy: 0.8170\n",
      "Epoch 186/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3898 - binary_accuracy: 0.8303 - val_loss: 0.4106 - val_binary_accuracy: 0.8170\n",
      "Epoch 187/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3894 - binary_accuracy: 0.8306 - val_loss: 0.4089 - val_binary_accuracy: 0.8223\n",
      "Epoch 188/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3902 - binary_accuracy: 0.8290 - val_loss: 0.4079 - val_binary_accuracy: 0.8249\n",
      "Epoch 189/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3892 - binary_accuracy: 0.8297 - val_loss: 0.4142 - val_binary_accuracy: 0.8143\n",
      "Epoch 190/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3895 - binary_accuracy: 0.8306 - val_loss: 0.4116 - val_binary_accuracy: 0.8143\n",
      "Epoch 191/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3893 - binary_accuracy: 0.8297 - val_loss: 0.4097 - val_binary_accuracy: 0.8196\n",
      "Epoch 192/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3893 - binary_accuracy: 0.8300 - val_loss: 0.4089 - val_binary_accuracy: 0.8223\n",
      "Epoch 193/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3893 - binary_accuracy: 0.8313 - val_loss: 0.4090 - val_binary_accuracy: 0.8223\n",
      "Epoch 194/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3894 - binary_accuracy: 0.8321 - val_loss: 0.4081 - val_binary_accuracy: 0.8223\n",
      "Epoch 195/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3887 - binary_accuracy: 0.8307 - val_loss: 0.4163 - val_binary_accuracy: 0.8249\n",
      "Epoch 196/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3886 - binary_accuracy: 0.8310 - val_loss: 0.4076 - val_binary_accuracy: 0.8276\n",
      "Epoch 197/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3889 - binary_accuracy: 0.8318 - val_loss: 0.4077 - val_binary_accuracy: 0.8276\n",
      "Epoch 198/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3886 - binary_accuracy: 0.8306 - val_loss: 0.4080 - val_binary_accuracy: 0.8249\n",
      "Epoch 199/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3888 - binary_accuracy: 0.8303 - val_loss: 0.4108 - val_binary_accuracy: 0.8170\n",
      "Epoch 200/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3886 - binary_accuracy: 0.8300 - val_loss: 0.4100 - val_binary_accuracy: 0.8196\n",
      "Epoch 201/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3887 - binary_accuracy: 0.8314 - val_loss: 0.4115 - val_binary_accuracy: 0.8196\n",
      "Epoch 202/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3884 - binary_accuracy: 0.8310 - val_loss: 0.4090 - val_binary_accuracy: 0.8223\n",
      "Epoch 203/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3885 - binary_accuracy: 0.8294 - val_loss: 0.4080 - val_binary_accuracy: 0.8223\n",
      "Epoch 204/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3881 - binary_accuracy: 0.8313 - val_loss: 0.4082 - val_binary_accuracy: 0.8223\n",
      "Epoch 205/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3881 - binary_accuracy: 0.8321 - val_loss: 0.4113 - val_binary_accuracy: 0.8170\n",
      "Epoch 206/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3883 - binary_accuracy: 0.8311 - val_loss: 0.4158 - val_binary_accuracy: 0.8276\n",
      "Epoch 207/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3882 - binary_accuracy: 0.8313 - val_loss: 0.4086 - val_binary_accuracy: 0.8223\n",
      "Epoch 208/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3878 - binary_accuracy: 0.8311 - val_loss: 0.4097 - val_binary_accuracy: 0.8196\n",
      "Epoch 209/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3874 - binary_accuracy: 0.8315 - val_loss: 0.4144 - val_binary_accuracy: 0.8170\n",
      "Epoch 210/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3877 - binary_accuracy: 0.8300 - val_loss: 0.4097 - val_binary_accuracy: 0.8223\n",
      "Epoch 211/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3879 - binary_accuracy: 0.8300 - val_loss: 0.4117 - val_binary_accuracy: 0.8196\n",
      "Epoch 212/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3877 - binary_accuracy: 0.8321 - val_loss: 0.4076 - val_binary_accuracy: 0.8276\n",
      "Epoch 213/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3884 - binary_accuracy: 0.8314 - val_loss: 0.4101 - val_binary_accuracy: 0.8196\n",
      "Epoch 214/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3875 - binary_accuracy: 0.8308 - val_loss: 0.4097 - val_binary_accuracy: 0.8223\n",
      "Epoch 215/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3877 - binary_accuracy: 0.8322 - val_loss: 0.4139 - val_binary_accuracy: 0.8196\n",
      "Epoch 216/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3875 - binary_accuracy: 0.8318 - val_loss: 0.4161 - val_binary_accuracy: 0.8276\n",
      "Epoch 217/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3874 - binary_accuracy: 0.8307 - val_loss: 0.4089 - val_binary_accuracy: 0.8223\n",
      "Epoch 218/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3878 - binary_accuracy: 0.8301 - val_loss: 0.4069 - val_binary_accuracy: 0.8223\n",
      "Epoch 219/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3872 - binary_accuracy: 0.8320 - val_loss: 0.4155 - val_binary_accuracy: 0.8276\n",
      "Epoch 220/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3872 - binary_accuracy: 0.8299 - val_loss: 0.4122 - val_binary_accuracy: 0.8196\n",
      "Epoch 221/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3870 - binary_accuracy: 0.8310 - val_loss: 0.4117 - val_binary_accuracy: 0.8196\n",
      "Epoch 222/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3867 - binary_accuracy: 0.8321 - val_loss: 0.4109 - val_binary_accuracy: 0.8170\n",
      "Epoch 223/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3870 - binary_accuracy: 0.8306 - val_loss: 0.4099 - val_binary_accuracy: 0.8223\n",
      "Epoch 224/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3873 - binary_accuracy: 0.8317 - val_loss: 0.4109 - val_binary_accuracy: 0.8170\n",
      "Epoch 225/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3865 - binary_accuracy: 0.8321 - val_loss: 0.4092 - val_binary_accuracy: 0.8223\n",
      "Epoch 226/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3864 - binary_accuracy: 0.8320 - val_loss: 0.4112 - val_binary_accuracy: 0.8170\n",
      "Epoch 227/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3867 - binary_accuracy: 0.8321 - val_loss: 0.4097 - val_binary_accuracy: 0.8223\n",
      "Epoch 228/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3866 - binary_accuracy: 0.8327 - val_loss: 0.4077 - val_binary_accuracy: 0.8276\n",
      "Epoch 229/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3862 - binary_accuracy: 0.8334 - val_loss: 0.4099 - val_binary_accuracy: 0.8196\n",
      "Epoch 230/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3863 - binary_accuracy: 0.8336 - val_loss: 0.4088 - val_binary_accuracy: 0.8223\n",
      "Epoch 231/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3866 - binary_accuracy: 0.8317 - val_loss: 0.4160 - val_binary_accuracy: 0.8249\n",
      "Epoch 232/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3863 - binary_accuracy: 0.8315 - val_loss: 0.4142 - val_binary_accuracy: 0.8223\n",
      "Epoch 233/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3860 - binary_accuracy: 0.8335 - val_loss: 0.4121 - val_binary_accuracy: 0.8223\n",
      "Epoch 234/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3860 - binary_accuracy: 0.8325 - val_loss: 0.4084 - val_binary_accuracy: 0.8223\n",
      "Epoch 235/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3860 - binary_accuracy: 0.8320 - val_loss: 0.4082 - val_binary_accuracy: 0.8223\n",
      "Epoch 236/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3857 - binary_accuracy: 0.8321 - val_loss: 0.4099 - val_binary_accuracy: 0.8223\n",
      "Epoch 237/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3859 - binary_accuracy: 0.8325 - val_loss: 0.4111 - val_binary_accuracy: 0.8170\n",
      "Epoch 238/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3856 - binary_accuracy: 0.8325 - val_loss: 0.4074 - val_binary_accuracy: 0.8223\n",
      "Epoch 239/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3856 - binary_accuracy: 0.8315 - val_loss: 0.4074 - val_binary_accuracy: 0.8223\n",
      "Epoch 240/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3855 - binary_accuracy: 0.8310 - val_loss: 0.4111 - val_binary_accuracy: 0.8196\n",
      "Epoch 241/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3855 - binary_accuracy: 0.8328 - val_loss: 0.4094 - val_binary_accuracy: 0.8223\n",
      "Epoch 242/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3852 - binary_accuracy: 0.8327 - val_loss: 0.4104 - val_binary_accuracy: 0.8223\n",
      "Epoch 243/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3852 - binary_accuracy: 0.8318 - val_loss: 0.4076 - val_binary_accuracy: 0.8223\n",
      "Epoch 244/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3852 - binary_accuracy: 0.8320 - val_loss: 0.4098 - val_binary_accuracy: 0.8223\n",
      "Epoch 245/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3853 - binary_accuracy: 0.8325 - val_loss: 0.4110 - val_binary_accuracy: 0.8223\n",
      "Epoch 246/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3851 - binary_accuracy: 0.8324 - val_loss: 0.4113 - val_binary_accuracy: 0.8196\n",
      "Epoch 247/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3851 - binary_accuracy: 0.8324 - val_loss: 0.4086 - val_binary_accuracy: 0.8223\n",
      "Epoch 248/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3849 - binary_accuracy: 0.8324 - val_loss: 0.4130 - val_binary_accuracy: 0.8223\n",
      "Epoch 249/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3853 - binary_accuracy: 0.8328 - val_loss: 0.4099 - val_binary_accuracy: 0.8223\n",
      "Epoch 250/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3851 - binary_accuracy: 0.8334 - val_loss: 0.4113 - val_binary_accuracy: 0.8196\n",
      "Epoch 251/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3849 - binary_accuracy: 0.8318 - val_loss: 0.4085 - val_binary_accuracy: 0.8223\n",
      "Epoch 252/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3850 - binary_accuracy: 0.8352 - val_loss: 0.4095 - val_binary_accuracy: 0.8223\n",
      "Epoch 253/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3847 - binary_accuracy: 0.8335 - val_loss: 0.4097 - val_binary_accuracy: 0.8223\n",
      "Epoch 254/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3849 - binary_accuracy: 0.8327 - val_loss: 0.4106 - val_binary_accuracy: 0.8223\n",
      "Epoch 255/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3849 - binary_accuracy: 0.8331 - val_loss: 0.4106 - val_binary_accuracy: 0.8249\n",
      "Epoch 256/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3846 - binary_accuracy: 0.8324 - val_loss: 0.4090 - val_binary_accuracy: 0.8223\n",
      "Epoch 257/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3844 - binary_accuracy: 0.8338 - val_loss: 0.4084 - val_binary_accuracy: 0.8249\n",
      "Epoch 258/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3845 - binary_accuracy: 0.8325 - val_loss: 0.4109 - val_binary_accuracy: 0.8249\n",
      "Epoch 259/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3844 - binary_accuracy: 0.8334 - val_loss: 0.4082 - val_binary_accuracy: 0.8223\n",
      "Epoch 260/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3841 - binary_accuracy: 0.8331 - val_loss: 0.4090 - val_binary_accuracy: 0.8223\n",
      "Epoch 261/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3848 - binary_accuracy: 0.8331 - val_loss: 0.4098 - val_binary_accuracy: 0.8249\n",
      "Epoch 262/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3843 - binary_accuracy: 0.8327 - val_loss: 0.4104 - val_binary_accuracy: 0.8249\n",
      "Epoch 263/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3839 - binary_accuracy: 0.8343 - val_loss: 0.4108 - val_binary_accuracy: 0.8249\n",
      "Epoch 264/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3839 - binary_accuracy: 0.8342 - val_loss: 0.4094 - val_binary_accuracy: 0.8223\n",
      "Epoch 265/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3837 - binary_accuracy: 0.8329 - val_loss: 0.4122 - val_binary_accuracy: 0.8196\n",
      "Epoch 266/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3837 - binary_accuracy: 0.8332 - val_loss: 0.4092 - val_binary_accuracy: 0.8223\n",
      "Epoch 267/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3839 - binary_accuracy: 0.8327 - val_loss: 0.4127 - val_binary_accuracy: 0.8223\n",
      "Epoch 268/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3837 - binary_accuracy: 0.8328 - val_loss: 0.4100 - val_binary_accuracy: 0.8249\n",
      "Epoch 269/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3838 - binary_accuracy: 0.8334 - val_loss: 0.4078 - val_binary_accuracy: 0.8196\n",
      "Epoch 270/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3841 - binary_accuracy: 0.8331 - val_loss: 0.4083 - val_binary_accuracy: 0.8196\n",
      "Epoch 271/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3835 - binary_accuracy: 0.8328 - val_loss: 0.4113 - val_binary_accuracy: 0.8249\n",
      "Epoch 272/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3835 - binary_accuracy: 0.8325 - val_loss: 0.4101 - val_binary_accuracy: 0.8249\n",
      "Epoch 273/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3834 - binary_accuracy: 0.8332 - val_loss: 0.4087 - val_binary_accuracy: 0.8223\n",
      "Epoch 274/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3832 - binary_accuracy: 0.8329 - val_loss: 0.4099 - val_binary_accuracy: 0.8249\n",
      "Epoch 275/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3831 - binary_accuracy: 0.8332 - val_loss: 0.4082 - val_binary_accuracy: 0.8196\n",
      "Epoch 276/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3833 - binary_accuracy: 0.8332 - val_loss: 0.4097 - val_binary_accuracy: 0.8249\n",
      "Epoch 277/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3832 - binary_accuracy: 0.8332 - val_loss: 0.4170 - val_binary_accuracy: 0.8302\n",
      "Epoch 278/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3836 - binary_accuracy: 0.8327 - val_loss: 0.4087 - val_binary_accuracy: 0.8223\n",
      "Epoch 279/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3832 - binary_accuracy: 0.8341 - val_loss: 0.4113 - val_binary_accuracy: 0.8249\n",
      "Epoch 280/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3828 - binary_accuracy: 0.8339 - val_loss: 0.4099 - val_binary_accuracy: 0.8249\n",
      "Epoch 281/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3830 - binary_accuracy: 0.8342 - val_loss: 0.4077 - val_binary_accuracy: 0.8196\n",
      "Epoch 282/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3826 - binary_accuracy: 0.8349 - val_loss: 0.4144 - val_binary_accuracy: 0.8223\n",
      "Epoch 283/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3828 - binary_accuracy: 0.8346 - val_loss: 0.4099 - val_binary_accuracy: 0.8249\n",
      "Epoch 284/400\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.3841 - binary_accuracy: 0.831 - 0s 2ms/step - loss: 0.3827 - binary_accuracy: 0.8329 - val_loss: 0.4088 - val_binary_accuracy: 0.8196\n",
      "Epoch 285/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3830 - binary_accuracy: 0.8349 - val_loss: 0.4096 - val_binary_accuracy: 0.8249\n",
      "Epoch 286/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3825 - binary_accuracy: 0.8334 - val_loss: 0.4128 - val_binary_accuracy: 0.8196\n",
      "Epoch 287/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3827 - binary_accuracy: 0.8338 - val_loss: 0.4102 - val_binary_accuracy: 0.8249\n",
      "Epoch 288/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3826 - binary_accuracy: 0.8339 - val_loss: 0.4103 - val_binary_accuracy: 0.8249\n",
      "Epoch 289/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3824 - binary_accuracy: 0.8356 - val_loss: 0.4138 - val_binary_accuracy: 0.8196\n",
      "Epoch 290/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3827 - binary_accuracy: 0.8363 - val_loss: 0.4085 - val_binary_accuracy: 0.8196\n",
      "Epoch 291/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3824 - binary_accuracy: 0.8336 - val_loss: 0.4101 - val_binary_accuracy: 0.8249\n",
      "Epoch 292/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3822 - binary_accuracy: 0.8339 - val_loss: 0.4076 - val_binary_accuracy: 0.8196\n",
      "Epoch 293/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3827 - binary_accuracy: 0.8353 - val_loss: 0.4096 - val_binary_accuracy: 0.8249\n",
      "Epoch 294/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3821 - binary_accuracy: 0.8336 - val_loss: 0.4084 - val_binary_accuracy: 0.8196\n",
      "Epoch 295/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3819 - binary_accuracy: 0.8341 - val_loss: 0.4108 - val_binary_accuracy: 0.8249\n",
      "Epoch 296/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3819 - binary_accuracy: 0.8339 - val_loss: 0.4111 - val_binary_accuracy: 0.8249\n",
      "Epoch 297/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3818 - binary_accuracy: 0.8334 - val_loss: 0.4119 - val_binary_accuracy: 0.8249\n",
      "Epoch 298/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3818 - binary_accuracy: 0.8338 - val_loss: 0.4136 - val_binary_accuracy: 0.8196\n",
      "Epoch 299/400\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 0.3819 - binary_accuracy: 0.8360 - val_loss: 0.4086 - val_binary_accuracy: 0.8223\n",
      "Epoch 300/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3818 - binary_accuracy: 0.8343 - val_loss: 0.4097 - val_binary_accuracy: 0.8249\n",
      "Epoch 301/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3818 - binary_accuracy: 0.8345 - val_loss: 0.4088 - val_binary_accuracy: 0.8223\n",
      "Epoch 302/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3818 - binary_accuracy: 0.8345 - val_loss: 0.4084 - val_binary_accuracy: 0.8196\n",
      "Epoch 303/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3817 - binary_accuracy: 0.8327 - val_loss: 0.4114 - val_binary_accuracy: 0.8249\n",
      "Epoch 304/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3813 - binary_accuracy: 0.8349 - val_loss: 0.4102 - val_binary_accuracy: 0.8249\n",
      "Epoch 305/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3813 - binary_accuracy: 0.8346 - val_loss: 0.4095 - val_binary_accuracy: 0.8223\n",
      "Epoch 306/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3818 - binary_accuracy: 0.8334 - val_loss: 0.4076 - val_binary_accuracy: 0.8196\n",
      "Epoch 307/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3816 - binary_accuracy: 0.8338 - val_loss: 0.4121 - val_binary_accuracy: 0.8249\n",
      "Epoch 308/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3818 - binary_accuracy: 0.8346 - val_loss: 0.4075 - val_binary_accuracy: 0.8196\n",
      "Epoch 309/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3816 - binary_accuracy: 0.8345 - val_loss: 0.4106 - val_binary_accuracy: 0.8249\n",
      "Epoch 310/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3809 - binary_accuracy: 0.8338 - val_loss: 0.4117 - val_binary_accuracy: 0.8249\n",
      "Epoch 311/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3811 - binary_accuracy: 0.8332 - val_loss: 0.4095 - val_binary_accuracy: 0.8249\n",
      "Epoch 312/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3811 - binary_accuracy: 0.8350 - val_loss: 0.4140 - val_binary_accuracy: 0.8223\n",
      "Epoch 313/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3811 - binary_accuracy: 0.8359 - val_loss: 0.4118 - val_binary_accuracy: 0.8249\n",
      "Epoch 314/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3811 - binary_accuracy: 0.8352 - val_loss: 0.4099 - val_binary_accuracy: 0.8223\n",
      "Epoch 315/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3810 - binary_accuracy: 0.8353 - val_loss: 0.4105 - val_binary_accuracy: 0.8249\n",
      "Epoch 316/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3811 - binary_accuracy: 0.8349 - val_loss: 0.4103 - val_binary_accuracy: 0.8249\n",
      "Epoch 317/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3807 - binary_accuracy: 0.8343 - val_loss: 0.4092 - val_binary_accuracy: 0.8223\n",
      "Epoch 318/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3807 - binary_accuracy: 0.8363 - val_loss: 0.4106 - val_binary_accuracy: 0.8223\n",
      "Epoch 319/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3807 - binary_accuracy: 0.8338 - val_loss: 0.4123 - val_binary_accuracy: 0.8249\n",
      "Epoch 320/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3803 - binary_accuracy: 0.8350 - val_loss: 0.4080 - val_binary_accuracy: 0.8170\n",
      "Epoch 321/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3806 - binary_accuracy: 0.8342 - val_loss: 0.4098 - val_binary_accuracy: 0.8223\n",
      "Epoch 322/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3809 - binary_accuracy: 0.8343 - val_loss: 0.4192 - val_binary_accuracy: 0.8329\n",
      "Epoch 323/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3805 - binary_accuracy: 0.8357 - val_loss: 0.4115 - val_binary_accuracy: 0.8249\n",
      "Epoch 324/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3801 - binary_accuracy: 0.8343 - val_loss: 0.4124 - val_binary_accuracy: 0.8249\n",
      "Epoch 325/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3804 - binary_accuracy: 0.8353 - val_loss: 0.4083 - val_binary_accuracy: 0.8196\n",
      "Epoch 326/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3802 - binary_accuracy: 0.8357 - val_loss: 0.4122 - val_binary_accuracy: 0.8249\n",
      "Epoch 327/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3805 - binary_accuracy: 0.8346 - val_loss: 0.4110 - val_binary_accuracy: 0.8249\n",
      "Epoch 328/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3803 - binary_accuracy: 0.8352 - val_loss: 0.4080 - val_binary_accuracy: 0.8170\n",
      "Epoch 329/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3804 - binary_accuracy: 0.8352 - val_loss: 0.4116 - val_binary_accuracy: 0.8249\n",
      "Epoch 330/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3801 - binary_accuracy: 0.8350 - val_loss: 0.4112 - val_binary_accuracy: 0.8249\n",
      "Epoch 331/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3804 - binary_accuracy: 0.8357 - val_loss: 0.4123 - val_binary_accuracy: 0.8249\n",
      "Epoch 332/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3801 - binary_accuracy: 0.8364 - val_loss: 0.4124 - val_binary_accuracy: 0.8249\n",
      "Epoch 333/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3798 - binary_accuracy: 0.8355 - val_loss: 0.4101 - val_binary_accuracy: 0.8223\n",
      "Epoch 334/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3799 - binary_accuracy: 0.8348 - val_loss: 0.4121 - val_binary_accuracy: 0.8249\n",
      "Epoch 335/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3795 - binary_accuracy: 0.8355 - val_loss: 0.4105 - val_binary_accuracy: 0.8223\n",
      "Epoch 336/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3805 - binary_accuracy: 0.8352 - val_loss: 0.4087 - val_binary_accuracy: 0.8196\n",
      "Epoch 337/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3796 - binary_accuracy: 0.8355 - val_loss: 0.4095 - val_binary_accuracy: 0.8196\n",
      "Epoch 338/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3795 - binary_accuracy: 0.8360 - val_loss: 0.4088 - val_binary_accuracy: 0.8196\n",
      "Epoch 339/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3797 - binary_accuracy: 0.8352 - val_loss: 0.4130 - val_binary_accuracy: 0.8249\n",
      "Epoch 340/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3792 - binary_accuracy: 0.8338 - val_loss: 0.4200 - val_binary_accuracy: 0.8302\n",
      "Epoch 341/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3802 - binary_accuracy: 0.8359 - val_loss: 0.4100 - val_binary_accuracy: 0.8249\n",
      "Epoch 342/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3788 - binary_accuracy: 0.8359 - val_loss: 0.4175 - val_binary_accuracy: 0.8276\n",
      "Epoch 343/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3793 - binary_accuracy: 0.8353 - val_loss: 0.4092 - val_binary_accuracy: 0.8196\n",
      "Epoch 344/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3795 - binary_accuracy: 0.8355 - val_loss: 0.4085 - val_binary_accuracy: 0.8196\n",
      "Epoch 345/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3793 - binary_accuracy: 0.8355 - val_loss: 0.4116 - val_binary_accuracy: 0.8249\n",
      "Epoch 346/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3792 - binary_accuracy: 0.8352 - val_loss: 0.4101 - val_binary_accuracy: 0.8223\n",
      "Epoch 347/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3791 - binary_accuracy: 0.8368 - val_loss: 0.4104 - val_binary_accuracy: 0.8223\n",
      "Epoch 348/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3793 - binary_accuracy: 0.8360 - val_loss: 0.4084 - val_binary_accuracy: 0.8196\n",
      "Epoch 349/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3794 - binary_accuracy: 0.8345 - val_loss: 0.4084 - val_binary_accuracy: 0.8170\n",
      "Epoch 350/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3794 - binary_accuracy: 0.8352 - val_loss: 0.4096 - val_binary_accuracy: 0.8196\n",
      "Epoch 351/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3792 - binary_accuracy: 0.8357 - val_loss: 0.4087 - val_binary_accuracy: 0.8196\n",
      "Epoch 352/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3788 - binary_accuracy: 0.8366 - val_loss: 0.4117 - val_binary_accuracy: 0.8249\n",
      "Epoch 353/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3787 - binary_accuracy: 0.8352 - val_loss: 0.4109 - val_binary_accuracy: 0.8223\n",
      "Epoch 354/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3789 - binary_accuracy: 0.8359 - val_loss: 0.4095 - val_binary_accuracy: 0.8196\n",
      "Epoch 355/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3789 - binary_accuracy: 0.8356 - val_loss: 0.4114 - val_binary_accuracy: 0.8223\n",
      "Epoch 356/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3788 - binary_accuracy: 0.8346 - val_loss: 0.4110 - val_binary_accuracy: 0.8223\n",
      "Epoch 357/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3787 - binary_accuracy: 0.8355 - val_loss: 0.4113 - val_binary_accuracy: 0.8223\n",
      "Epoch 358/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3793 - binary_accuracy: 0.8364 - val_loss: 0.4102 - val_binary_accuracy: 0.8223\n",
      "Epoch 359/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3786 - binary_accuracy: 0.8360 - val_loss: 0.4096 - val_binary_accuracy: 0.8196\n",
      "Epoch 360/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3789 - binary_accuracy: 0.8360 - val_loss: 0.4114 - val_binary_accuracy: 0.8223\n",
      "Epoch 361/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3786 - binary_accuracy: 0.8350 - val_loss: 0.4092 - val_binary_accuracy: 0.8196\n",
      "Epoch 362/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3785 - binary_accuracy: 0.8363 - val_loss: 0.4098 - val_binary_accuracy: 0.8196\n",
      "Epoch 363/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3784 - binary_accuracy: 0.8363 - val_loss: 0.4140 - val_binary_accuracy: 0.8276\n",
      "Epoch 364/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3784 - binary_accuracy: 0.8362 - val_loss: 0.4082 - val_binary_accuracy: 0.8223\n",
      "Epoch 365/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3787 - binary_accuracy: 0.8357 - val_loss: 0.4143 - val_binary_accuracy: 0.8223\n",
      "Epoch 366/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3783 - binary_accuracy: 0.8355 - val_loss: 0.4098 - val_binary_accuracy: 0.8196\n",
      "Epoch 367/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3784 - binary_accuracy: 0.8355 - val_loss: 0.4107 - val_binary_accuracy: 0.8196\n",
      "Epoch 368/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3782 - binary_accuracy: 0.8367 - val_loss: 0.4117 - val_binary_accuracy: 0.8223\n",
      "Epoch 369/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3781 - binary_accuracy: 0.8371 - val_loss: 0.4123 - val_binary_accuracy: 0.8223\n",
      "Epoch 370/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3783 - binary_accuracy: 0.8363 - val_loss: 0.4136 - val_binary_accuracy: 0.8276\n",
      "Epoch 371/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3780 - binary_accuracy: 0.8357 - val_loss: 0.4117 - val_binary_accuracy: 0.8170\n",
      "Epoch 372/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3784 - binary_accuracy: 0.8370 - val_loss: 0.4109 - val_binary_accuracy: 0.8223\n",
      "Epoch 373/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3780 - binary_accuracy: 0.8366 - val_loss: 0.4116 - val_binary_accuracy: 0.8196\n",
      "Epoch 374/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3778 - binary_accuracy: 0.8359 - val_loss: 0.4099 - val_binary_accuracy: 0.8196\n",
      "Epoch 375/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3780 - binary_accuracy: 0.8368 - val_loss: 0.4123 - val_binary_accuracy: 0.8223\n",
      "Epoch 376/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3781 - binary_accuracy: 0.8366 - val_loss: 0.4108 - val_binary_accuracy: 0.8223\n",
      "Epoch 377/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3776 - binary_accuracy: 0.8360 - val_loss: 0.4122 - val_binary_accuracy: 0.8170\n",
      "Epoch 378/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3776 - binary_accuracy: 0.8357 - val_loss: 0.4103 - val_binary_accuracy: 0.8196\n",
      "Epoch 379/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3776 - binary_accuracy: 0.8368 - val_loss: 0.4110 - val_binary_accuracy: 0.8196\n",
      "Epoch 380/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3775 - binary_accuracy: 0.8363 - val_loss: 0.4086 - val_binary_accuracy: 0.8196\n",
      "Epoch 381/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3776 - binary_accuracy: 0.8353 - val_loss: 0.4101 - val_binary_accuracy: 0.8196\n",
      "Epoch 382/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3776 - binary_accuracy: 0.8366 - val_loss: 0.4126 - val_binary_accuracy: 0.8249\n",
      "Epoch 383/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3775 - binary_accuracy: 0.8360 - val_loss: 0.4111 - val_binary_accuracy: 0.8223\n",
      "Epoch 384/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3778 - binary_accuracy: 0.8356 - val_loss: 0.4116 - val_binary_accuracy: 0.8196\n",
      "Epoch 385/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3773 - binary_accuracy: 0.8367 - val_loss: 0.4107 - val_binary_accuracy: 0.8223\n",
      "Epoch 386/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3772 - binary_accuracy: 0.8359 - val_loss: 0.4126 - val_binary_accuracy: 0.8170\n",
      "Epoch 387/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3771 - binary_accuracy: 0.8375 - val_loss: 0.4087 - val_binary_accuracy: 0.8196\n",
      "Epoch 388/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3777 - binary_accuracy: 0.8362 - val_loss: 0.4097 - val_binary_accuracy: 0.8196\n",
      "Epoch 389/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3773 - binary_accuracy: 0.8359 - val_loss: 0.4090 - val_binary_accuracy: 0.8170\n",
      "Epoch 390/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3771 - binary_accuracy: 0.8360 - val_loss: 0.4129 - val_binary_accuracy: 0.8276\n",
      "Epoch 391/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3772 - binary_accuracy: 0.8364 - val_loss: 0.4112 - val_binary_accuracy: 0.8223\n",
      "Epoch 392/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3769 - binary_accuracy: 0.8374 - val_loss: 0.4127 - val_binary_accuracy: 0.8223\n",
      "Epoch 393/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3769 - binary_accuracy: 0.8374 - val_loss: 0.4113 - val_binary_accuracy: 0.8196\n",
      "Epoch 394/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3768 - binary_accuracy: 0.8380 - val_loss: 0.4115 - val_binary_accuracy: 0.8223\n",
      "Epoch 395/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3769 - binary_accuracy: 0.8384 - val_loss: 0.4118 - val_binary_accuracy: 0.8170\n",
      "Epoch 396/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3774 - binary_accuracy: 0.8371 - val_loss: 0.4140 - val_binary_accuracy: 0.8249\n",
      "Epoch 397/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3774 - binary_accuracy: 0.8363 - val_loss: 0.4112 - val_binary_accuracy: 0.8196\n",
      "Epoch 398/400\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.3766 - binary_accuracy: 0.8371 - val_loss: 0.4135 - val_binary_accuracy: 0.8249\n",
      "Epoch 399/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3768 - binary_accuracy: 0.8362 - val_loss: 0.4112 - val_binary_accuracy: 0.8196\n",
      "Epoch 400/400\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 0.3770 - binary_accuracy: 0.8367 - val_loss: 0.4117 - val_binary_accuracy: 0.8223\n"
     ]
    }
   ],
   "source": [
    "history = lr_model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=400,\n",
    "    batch_size=128,\n",
    "    validation_split=0.05,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_binary_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.377384</td>\n",
       "      <td>0.837128</td>\n",
       "      <td>0.414007</td>\n",
       "      <td>0.824934</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.377445</td>\n",
       "      <td>0.836290</td>\n",
       "      <td>0.411233</td>\n",
       "      <td>0.819629</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.376605</td>\n",
       "      <td>0.837128</td>\n",
       "      <td>0.413505</td>\n",
       "      <td>0.824934</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.376788</td>\n",
       "      <td>0.836150</td>\n",
       "      <td>0.411200</td>\n",
       "      <td>0.819629</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.376967</td>\n",
       "      <td>0.836709</td>\n",
       "      <td>0.411701</td>\n",
       "      <td>0.822281</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  binary_accuracy  val_loss  val_binary_accuracy  epoch\n",
       "395  0.377384         0.837128  0.414007             0.824934    395\n",
       "396  0.377445         0.836290  0.411233             0.819629    396\n",
       "397  0.376605         0.837128  0.413505             0.824934    397\n",
       "398  0.376788         0.836150  0.411200             0.819629    398\n",
       "399  0.376967         0.836709  0.411701             0.822281    399"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df['epoch'] = history.epoch\n",
    "history_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f659468c390>]"
      ]
     },
     "execution_count": 836,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(history_df['epoch'], history_df['loss'], label='Training')\n",
    "plt.plot(history_df['epoch'], history_df['val_loss'], label='Validation', linestyle='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2280 - binary_accuracy: 0.9221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.228025883436203, 0.9220778942108154]"
      ]
     },
     "execution_count": 837,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.evaluate(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lr_model.predict(X_val)\n",
    "pred = pred > .5\n",
    "pred =(pred[:,0]).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive:  33\n",
      "True Negative:  38\n",
      "False Positive:  1\n",
      "false Negative:  5\n",
      "Precision:  0.9705882352941176\n",
      "Recall:  0.868421052631579\n",
      "F1 Score:  0.9166666666666667\n"
     ]
    }
   ],
   "source": [
    "tp = np.logical_and(pred == 1, Y_val == 1).sum()  # true positive\n",
    "tn = np.logical_and(pred == 0, Y_val == 0).sum()  # true negative\n",
    "fp = np.logical_and(pred == 1, Y_val == 0).sum()  # false positive\n",
    "fn = np.logical_and(pred == 0, Y_val == 1).sum()  # false negative\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print(\"True Positive: \", tp)\n",
    "print(\"True Negative: \", tn)\n",
    "print(\"False Positive: \", fp)\n",
    "print(\"false Negative: \", fn)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayConfusionMatrix(y_test, pred, dataset):\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(\n",
    "        y_test,\n",
    "        pred,\n",
    "        display_labels=[\"Not Disaster\",\"Disaster\"],\n",
    "        cmap=plt.cm.Blues\n",
    "    )\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "    f1_score = tp / (tp+((fn+fp)/2))\n",
    "\n",
    "    disp.ax_.set_title(\"Confusion Matrix on \" + dataset + \" Dataset -- F1 Score: \" + str(f1_score.round(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "displayConfusionMatrix(Y_val, pred, \"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of test_padded:  (3263, 182)\n"
     ]
    }
   ],
   "source": [
    "test_tokenized = tokenize(df_test[\"text\"])\n",
    "test_padded = pad_tokens(test_tokenized, max_len)\n",
    "print(\"shape of test_padded: \", test_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of test attention mask:  (3263, 182)\n"
     ]
    }
   ],
   "source": [
    "test_attention_mask = get_attention_mask(test_padded)\n",
    "print(\"shape of test attention mask: \", test_attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_ids = tf.convert_to_tensor(test_padded, dtype=tf.int32)\n",
    "test_attention_mask = tf.convert_to_tensor(test_attention_mask, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of test_feature vectors:  (3263, 768)\n"
     ]
    }
   ],
   "source": [
    "test_features = get_features(test_input_ids, test_attention_mask, \"data/E3_test.npy\")\n",
    "print(\"shape of test_feature vectors: \", test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = lr_model.predict(X_test)\n",
    "pred_test = pred_test > .5\n",
    "pred_test =(pred_test[:,0]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0\n",
       "2   3       0\n",
       "3   9       0\n",
       "4  11       0"
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission[\"target\"] = pred_test\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3263.000000</td>\n",
       "      <td>3263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5427.152927</td>\n",
       "      <td>0.381244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3146.427221</td>\n",
       "      <td>0.485767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2683.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8176.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10875.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       target\n",
       "count   3263.000000  3263.000000\n",
       "mean    5427.152927     0.381244\n",
       "std     3146.427221     0.485767\n",
       "min        0.000000     0.000000\n",
       "25%     2683.000000     0.000000\n",
       "50%     5500.000000     0.000000\n",
       "75%     8176.000000     1.000000\n",
       "max    10875.000000     1.000000"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"data/submission3.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
